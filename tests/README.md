# Tests de Triskel API

Suite completa de tests con **nivel de exigencia alta** (70%+ cobertura) para garantizar la calidad y mantenibilidad del c√≥digo.

## Estructura de Tests

```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Fixtures compartidas y mocks
‚îú‚îÄ‚îÄ test_auth.py             # Tests existentes de Auth (17 casos)
‚îú‚îÄ‚îÄ unit/                    # Tests unitarios (60% del esfuerzo)
‚îÇ   ‚îú‚îÄ‚îÄ test_player_models.py
‚îÇ   ‚îú‚îÄ‚îÄ test_player_schemas.py
‚îÇ   ‚îú‚îÄ‚îÄ test_player_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_game_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_game_schemas.py
‚îÇ   ‚îî‚îÄ‚îÄ test_event_service.py
‚îú‚îÄ‚îÄ integration/             # Tests de integraci√≥n (30% del esfuerzo)
‚îÇ   ‚îú‚îÄ‚îÄ test_player_adapter.py
‚îÇ   ‚îî‚îÄ‚îÄ test_auth_middleware.py
‚îî‚îÄ‚îÄ e2e/                     # Tests end-to-end (10% del esfuerzo)
    ‚îú‚îÄ‚îÄ test_game_workflow.py
    ‚îî‚îÄ‚îÄ (m√°s flujos E2E pueden agregarse)
```

## Instalaci√≥n de Dependencias

```bash
# Instalar dependencias de testing
pip install pytest pytest-asyncio pytest-cov

# O usar requirements.txt si ya incluye estas dependencias
pip install -r requirements.txt
```

## Ejecutar Tests

### Todos los tests con cobertura
```bash
pytest
```

### Solo tests unitarios
```bash
pytest -m unit
```

### Solo tests de integraci√≥n
```bash
pytest -m integration
```

### Solo tests E2E
```bash
pytest -m e2e
```

### Tests de seguridad
```bash
pytest -m security
```

### Tests de casos l√≠mite
```bash
pytest -m edge_case
```

### Ver cobertura detallada
```bash
pytest --cov=app --cov-report=html
# Luego abrir htmlcov/index.html en el navegador
```

### Tests con salida verbose
```bash
pytest -v
```

### Tests de un archivo espec√≠fico
```bash
pytest tests/unit/test_player_service.py
```

### Tests de una clase espec√≠fica
```bash
pytest tests/unit/test_player_service.py::TestPlayerStatsUpdate
```

### Tests de un caso espec√≠fico
```bash
pytest tests/unit/test_player_service.py::TestPlayerStatsUpdate::test_moral_alignment_all_good_choices
```

## Marcadores (Markers)

Los tests est√°n organizados con marcadores para filtrar f√°cilmente:

- `@pytest.mark.unit` - Tests unitarios de l√≥gica de negocio
- `@pytest.mark.integration` - Tests de integraci√≥n con adapters
- `@pytest.mark.e2e` - Tests end-to-end de flujos completos
- `@pytest.mark.slow` - Tests que tardan m√°s de 1 segundo
- `@pytest.mark.security` - Tests de seguridad y autorizaci√≥n
- `@pytest.mark.edge_case` - Tests de casos l√≠mite y extremos
- `@pytest.mark.requires_firebase` - Tests que requieren mock de Firebase
- `@pytest.mark.requires_db` - Tests que requieren base de datos SQL

## Objetivo de Cobertura

**Meta: 70%+ de cobertura de c√≥digo**

El archivo `pytest.ini` est√° configurado con `--cov-fail-under=70`, lo que significa que el build fallar√° si la cobertura es menor al 70%.

### √Åreas con Alta Cobertura

‚úÖ **Players Domain**
- Modelos y validaciones (Pydantic)
- Schemas de entrada/salida
- L√≥gica de negocio (PlayerService)
- C√°lculo de moral alignment
- Actualizaci√≥n de estad√≠sticas

‚úÖ **Games Domain**
- Ciclo de vida de partidas
- Validaci√≥n de partida activa
- Progresi√≥n de niveles
- Finalizaci√≥n de partidas

‚úÖ **Events Domain**
- Creaci√≥n individual y batch
- Validaci√≥n de jugadores
- Queries con filtros

‚úÖ **Auth Domain** (ya existente)
- Validaci√≥n de contrase√±as
- Hashing y verificaci√≥n
- Tokens JWT

### √Åreas a Expandir (Opcionales)

‚ö†Ô∏è **API Endpoints** - Agregar m√°s tests E2E para endpoints completos
‚ö†Ô∏è **Middleware** - Tests de autenticaci√≥n con casos reales
‚ö†Ô∏è **Validators** - Tests de validadores personalizados

## Fixtures Disponibles

### Datos de Prueba
- `player_id`, `player_token` - IDs y tokens √∫nicos
- `sample_player`, `new_player` - Jugadores de prueba
- `sample_player_stats` - Estad√≠sticas de jugador
- `active_game`, `completed_game`, `new_game` - Partidas de prueba
- `sample_event`, `level_start_event` - Eventos de prueba

### Mocks
- `mock_firestore_client` - Cliente mock de Firestore
- `mock_db_session` - Sesi√≥n mock de SQL
- `mock_player_repository` - Repositorio mock de players
- `mock_game_repository` - Repositorio mock de games
- `mock_event_repository` - Repositorio mock de events

### Autenticaci√≥n
- `admin_jwt_token` - Token JWT de admin v√°lido
- `expired_jwt_token` - Token JWT expirado
- `api_key` - API Key v√°lida
- `api_client` - Cliente de prueba de FastAPI
- `authenticated_api_client` - Cliente con JWT
- `player_api_client` - Cliente con player token

### Utilidades
- `assert_valid_uuid` - Validar que un string es UUID
- `assert_recent_timestamp` - Validar timestamp reciente
- `fixed_datetime`, `past_datetime`, `future_datetime` - Timestamps fijos

## Mejores Pr√°cticas

### 1. Usa fixtures en lugar de crear datos manualmente
```python
# ‚úÖ Bien
def test_create_player(sample_player):
    assert sample_player.username == "test_player"

# ‚ùå Mal
def test_create_player():
    player = Player(username="test", ...)
```

### 2. Marca los tests apropiadamente
```python
@pytest.mark.unit
@pytest.mark.edge_case
def test_games_completed_cannot_exceed_games_played():
    ...
```

### 3. Usa mocks para aislar dependencias
```python
def test_create_player(mock_player_repository):
    mock_player_repository.get_by_username.return_value = None
    # Test aislado sin tocar Firebase
```

### 4. Nombra tests descriptivamente
```python
# ‚úÖ Bien
def test_moral_alignment_all_good_choices():
    ...

# ‚ùå Mal
def test_alignment():
    ...
```

### 5. Agrupa tests relacionados en clases
```python
@pytest.mark.unit
class TestPlayerStatsUpdate:
    def test_update_stats_completed_game(self):
        ...

    def test_update_stats_abandoned_game(self):
        ...
```

## Integraci√≥n Continua (CI/CD)

Agrega esto a tu pipeline de CI:

```yaml
# .github/workflows/tests.yml
- name: Run tests with coverage
  run: |
    pytest --cov=app --cov-report=xml

- name: Upload coverage to Codecov
  uses: codecov/codecov-action@v3
  with:
    file: ./coverage.xml
```

## Debugging Tests

### Ver print statements
```bash
pytest -s
```

### Detener en el primer fallo
```bash
pytest -x
```

### Ver traceback completo
```bash
pytest --tb=long
```

### Modo debugging interactivo
```bash
pytest --pdb
```

## Contribuir Nuevos Tests

Al agregar nuevos tests:

1. **Determina el tipo** - ¬øEs unitario, integraci√≥n o E2E?
2. **Usa fixtures existentes** - Revisa `conftest.py`
3. **Marca apropiadamente** - Usa `@pytest.mark.*`
4. **Cubre edge cases** - No solo happy paths
5. **Documenta casos complejos** - Agrega docstrings
6. **Verifica cobertura** - Debe mantenerse >70%

## Reportes de Cobertura

Despu√©s de ejecutar `pytest --cov`, se generan:

- **Terminal**: Reporte resumido con l√≠neas faltantes
- **htmlcov/index.html**: Reporte HTML interactivo con c√≥digo resaltado
- L√≠neas en rojo = no cubiertas
- L√≠neas en verde = cubiertas

## Troubleshooting

### Error: "Module not found"
```bash
# Aseg√∫rate de estar en el directorio ra√≠z
cd /path/to/Triskel-API
pytest
```

### Error: "No module named 'pytest'"
```bash
pip install pytest pytest-asyncio pytest-cov
```

### Tests muy lentos
```bash
# Ver los 10 tests m√°s lentos
pytest --durations=10
```

### Firebase credential errors
Los mocks deber√≠an evitar esto, pero si ocurre:
```bash
# Ejecuta solo tests que no requieren Firebase
pytest -m "not requires_firebase"
```

## Estad√≠sticas Actuales

- **Total de tests**: ~80+ casos
- **Cobertura objetivo**: 70%+
- **Tiempo de ejecuci√≥n**: <10 segundos (con mocks)
- **Dominios cubiertos**: Players, Games, Events, Auth

---

**¬°Happy Testing! üß™**

Los tests no solo verifican que el c√≥digo funciona, sino que ayudan a:
- Detectar regresiones temprano
- Documentar comportamiento esperado
- Facilitar refactoring seguro
- Mejorar el dise√±o del c√≥digo
